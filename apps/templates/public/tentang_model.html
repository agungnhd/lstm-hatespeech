{% extends 'public/base.html' %}

<!-- Block Head -->
{% block head %}
<title>Tentang Model &mdash; by AgungNH</title>

{% endblock %}

<!-- Block Content -->
{% block content %}

	{% include 'public/feature.html' %}

	<!-- About section -->
	<section class="ftco-about img ftco-section" id="about-section">
		<div class="container">
			<div class="row no-gutters">
				<div class="col-md-12 col-lg-12 pl-md-5">
					<div class="col-md-12 heading-section ftco-animate">
						<h2 class="mb-4">Long-Short Term Memory (LSTM)</h2>
						<br>
						<div class="text-about">
							<h4 class="heading">Recurrent Neural Network</h4>
							<div class="img mx-auto col-md-9 col-lg-9">
								<img src="{{url_for('static', filename='public/images/RNN-unrolled-1.png')}}" class="img-fluid" alt="rnn-unrolled">
							</div><br>
							<p style="text-align:justify">
								<i>Recurrent Neural Network</i> (RNN) merupakan jaringan saraf berulang. 
								Dikatakan jaringan saraf berulang karena nilai <i>neuron</i> pada <i>hidden layer</i> sebelumnya akan digunakan kembali sebagai data input. 
								Penggunaan <i>neuron</i> pada <i>hidden layer</i> akan disimpan ke dalam sebuah <i>layer</i> yang dinamakan <i>context layer</i>. 
								Nilai <i>neuron</i> pada <i>context layer</i> akan terus update hingga kondisi RNN terpenuhi.
							</p>
							<br>
							<h4>Long Short Term Memory</h4>
							<div class="img mx-auto col-lg-9">
								<img src="{{url_for('static', filename='public/images/LSTM3-chain-1.png')}}" class="img-fluid" alt="lstm-chain">
							</div><br>
							<p style="text-align:justify"> 
								<i>Long Short Term Memory</i> (LSTM) merupakan jenis modul pemrosesan lain untuk <i>Recurrent Neural Network</i> (RNN). 
								Seperti RNN, Jaringan LSTM juga terdiri dari modul-modul pemrosesan berulang, yang membedakan adalah modul pembentuk jaringan LSTM adalah modul LSTM sebelumnya. 
								Perbedaan lainya adalah adanya tambahan sinyal yang diberikan dari satu langkah waktu kelangkah waktu berikutnya, yaitu konteks. 
								LSTM didesain untuk mengatasi <i>vanisihing gradients</i> menggunakan mekanisme gerbang (<i>gate</i>) yang sebelumnya menjadi masalah pada RNN. 
								Keunggulan metode LSTM dibandingkan dengan RNN adalah adanya arsitektur mengingat dan melupakan output yang akan diproses kembali menjadi input. 
								Selain itu, keunggulan lain yang dimiliki oleh metode ini adalah adanya kemampuan untuk mempertahankan error saat melakukan <i>backpropagation</i> yang memungkinkan kesalahan yang terjadi tidak akan mengalami peningkatan (Zhang, 2016).
							</p>
							<div class="img mx-auto col-lg-2">
								<img src="{{url_for('static', filename='public/images/LSTM3-gate.png')}}" class="img-fluid" alt="lstm-chain">
							</div><br>
							<p style="text-align:justify"> 
								Kunci utama dalam LSTM adalah cell state, yaitu garis horizontal yang berjalan di atas diagram. 
								Dengan beberapa interaksi linear kecil, maka informasi yang ada dengan mudah akan mengalir tanpa mengalami perubahan. 
								LSTM memiliki kemampuan untuk menghapus dan menambahkan informasi ke dalam sel yang dikontrol penuh oleh gerbang. 
								Gerbang-gerbang yang ada tersusun dari lapisan saraf sigmoid dan searah operasi multiplikasi. 
								Output yang dihasilkan oleh lapisan sigmoid adalah bilangan biner 1 atau 0. 
								Angka 0 menunjukkan bahwa tidak akan ada informasi yang diteruskan, sedangkan angka 1 menunjukkan bahwa semua informasi akan diteruskan.
							</p>
							<div class="img mx-auto col-lg-9">
								<img src="{{url_for('static', filename='public/images/LSTM3-focus-f.png')}}" class="img-fluid" alt="lstm-chain">
							</div><br>
							<p style="text-align:justify"> 
								Langkah pertama dalam membangun jaringan LSTM adalah mengidentifikasi informasi yang tidak perlu dan akan dihapus dari sel. 
								Proses identifikasi dan pengecualian akan ditentukan oleh fungsi sigmoid, yang mengambil dari unit LSTM terakhir yang ditunjukkan oleh (ℎ𝑡−1) pada waktu t-1 dan arus input yang ditunjukkan oleh 𝑋𝑡 pada waktu t. 
								Gerbang ini disebut sebagai forget gate di mana 𝑓𝑡 adalah vector dengan nilai 0 atau 1, sesuai dengan keadaan sel yang ditunjukkan oleh (𝑐𝑡−1). 
							</p>
							<div class="img mx-auto col-lg-9">
								<img src="{{url_for('static', filename='public/images/LSTM3-focus-i.png')}}" class="img-fluid" alt="lstm-chain">
							</div><br>
							<p style="text-align:justify"> 
								Langkah selanjutnya adalah memutuskan dan menyimpan informasi dari input baru yang dilambangkan dengan 𝑋𝑡 dalam sel untuk memperbarui cell state. 
								Pada langkah ini ada dua bagian yang dilalui, pertama adalah lapisan sigmoid dan kedua adalah tanh serta untuk memperbarui cell state. 
								Lapisan sigmoid akan memutuskan apakah informasi akan diabaikan atau diperbarui dengan mengeluarkan output berupa 0 atau 1. 
								Kemudian lapisan tanh akan memberikan bobot pada nilai yang dilewati berdasarkan level kepentingannya dengan memberikan nilai antara -1 sampai 1. 
							</p>
							<div class="img mx-auto col-lg-9">
								<img src="{{url_for('static', filename='public/images/LSTM3-focus-C.png')}}" class="img-fluid" alt="lstm-chain">
							</div><br>
							<p style="text-align:justify"> 
								Langkah selanjutnya adalah memperbaharui nilai cell state. 
								Kedua nilai yang telah dihasilkan pada langkah kedua kemudian akan dikalikan untuk memperbarui cell state. 
								Memori baru ini kemudian akan ditambahkan ke memori lama yang dilambangkan dengan 𝐶𝑡−1 dan akan menghasilkan memori yang baru yang dilambangkan 𝐶𝑡.
							</p>
							<div class="img mx-auto col-lg-9">
								<img src="{{url_for('static', filename='public/images/LSTM3-focus-o.png')}}" class="img-fluid" alt="lstm-chain">
							</div><br>
							<p style="text-align:justify"> 
								Pada langkah terakhir, nilai output yang dilambangkan ℎ𝑡 bersumber dari nilai pada sel output yang dilambangkan dengan 𝑂𝑡 yang telah mengalami proses pemfilteran. 
								Pertama lapisan sigmoid memutuskan bagian sel mana yang menjadi output. 
								Selanjutnya, output dari gerbang sigmoid (𝑂𝑡) dikalikan dengan nilai baru yang dihasilkan oleh lapisan tanh dari cell state (𝐶𝑡), nilai yang dihasilkan berkisar antara -1 sampai 1. 
							</p>
						</div>
					</div>
				</div>
			</div>
		</div>
	</section>

<!-- End of Content -->
{% endblock %}